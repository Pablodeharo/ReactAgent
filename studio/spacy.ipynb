{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "951bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los DataFrames (ajusta las rutas de los archivos a tu estructura)\n",
    "df_obras = pd.read_csv(r\"C:\\Users\\Lucas\\Desktop\\Socrates\\llm_proyect\\data\\corpus\\escritos.csv\")\n",
    "df_dialogos = pd.read_csv(r\"C:\\Users\\Lucas\\Desktop\\Socrates\\llm_proyect\\data\\corpus\\dialogos.csv\")\n",
    "df_argumentos = pd.read_csv(r\"C:\\Users\\Lucas\\Desktop\\Socrates\\llm_proyect\\data\\corpus\\argumentos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a540c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   contenido  69 non-null     object\n",
      " 1   titulo     69 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   dialogo  35 non-null     object\n",
      " 1   titulo   35 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 692.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   argumento  16 non-null     object\n",
      " 1   titulo     16 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 388.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_obras.info()\n",
    "df_dialogos.info()\n",
    "df_argumentos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd6a9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy_transformers\\layers\\hf_shim.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self._model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_dep_news_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed4e8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Procesamiento de documentos pasa el texto por el pipline completo de spacy.\n",
    "\n",
    "Incluye:\n",
    "- Tokenizacion\n",
    "- Etiquetado POS(part of speech)\n",
    "- Analisis de dependencias\n",
    "- Reconocimiento de entidades nombradas(NER)\n",
    "\n",
    "Atributos principales:\n",
    "- doc.ents las entidades nombradas reconocidas\n",
    "- token.pos_ : La categoria gramatical de cada token\n",
    "- token.dep_ : La relacion de dependencia sintactica\n",
    "- token.head : El token del que depende el token actual\n",
    "\"\"\"\n",
    "# Función para procesar los diálogos y extraer entidades y temas\n",
    "def procesar_dialogo(dialogo):\n",
    "    doc = nlp(dialogo)\n",
    "    \n",
    "    # Extraer entidades\n",
    "    entidades = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # Extraer sustantivos (posibles temas)\n",
    "    temas = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "    \n",
    "    # Analizar las dependencias y relaciones\n",
    "    dependencias = [\"_\".join([token.text, token.dep_, token.head.text]) for token in doc]\n",
    "    \n",
    "    return entidades, temas, dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a597449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que las columnas no contengan valores nulos o vacíos antes de procesarlas\n",
    "def limpiar_columna(columna):\n",
    "    # Reemplazar valores nulos por cadena vacía\n",
    "    columna = columna.fillna('')\n",
    "    # Eliminar espacios al principio y al final de cada entrada\n",
    "    columna = columna.apply(lambda x: x.strip())\n",
    "    return columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2da6e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar las columnas relevantes\n",
    "df_dialogos['dialogo'] = limpiar_columna(df_dialogos['dialogo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función procesar_dialogo a la columna 'dialogo' de df_dialogos\n",
    "df_dialogos['entidades'], df_dialogos['temas'], df_dialogos['dependencias'] = zip(*df_dialogos['dialogo'].apply(procesar_dialogo))\n",
    "\n",
    "# Verificar las primeras filas para asegurarse de que las nuevas columnas están correctas\n",
    "print(df_dialogos[['titulo', 'dialogo', 'entidades', 'temas', 'dependencias']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dialogos['entidades'] = limpiar_columna(df_dialogos['entidades'])\n",
    "df_dialogos['temas'] = limpiar_columna(df_dialogos['temas'])\n",
    "df_dialogos['dependencias'] = limpiar_columna(df_dialogos['dependencias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b37d02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   dialogo  35 non-null     object\n",
      " 1   titulo   35 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_dialogos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a50dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8aa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adecf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las listas a texto (separado por espacios)\n",
    "df_dialogos['entidades'] = df_dialogos['entidades'].apply(lambda x: ' '.join(x))\n",
    "df_dialogos['temas'] = df_dialogos['temas'].apply(lambda x: ' '.join(x))\n",
    "df_dialogos['dependencias'] = df_dialogos['dependencias'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e43fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         titulo entidades                                              temas  \\\n",
      "0    Testamento        []  [testamento, mención, jardín, discípulos, test...   \n",
      "1      Clitofon        []  [conversaciones, lecciones, sofista, discurso,...   \n",
      "2  Definiciones        []  [definiciones, clases, interés, orden, doctrin...   \n",
      "3        Cartas        []  [correspondencia, cartas, personajes, cartas, ...   \n",
      "4   De lo justo        []  [comienzo, asunto, diálogo, pesar, ignorancia,...   \n",
      "\n",
      "                                        dependencias  \n",
      "0  [Este_det_testamento, testamento_nsubj_suyo, ,...  \n",
      "1  [Clitofon_nsubj_defiende, ,_punct_acusado, acu...  \n",
      "2  [Estas_det_definiciones, ciento_nummod_definic...  \n",
      "3  [La_det_correspondencia, correspondencia_nsubj...  \n",
      "4  [¿_punct_justo, Qué_nsubj_justo, es_cop_justo,...  \n"
     ]
    }
   ],
   "source": [
    "# Procesar todos los textos de las obras\n",
    "df_obras['entidades'], df_obras['temas'], df_obras['dependencias'] = zip(*df_obras['contenido'].apply(procesar_dialogo))\n",
    "\n",
    "# Mostrar los resultados procesados para las primeras obras\n",
    "print(df_obras[['titulo', 'entidades', 'temas', 'dependencias']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2ee89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dialogos['dialogo'] = df_dialogos['dialogo'].astype(str)\n",
    "df_dialogos['entidades'] = df_dialogos['entidades'].astype(str)\n",
    "df_dialogos['temas'] = df_dialogos['temas'].astype(str)\n",
    "df_dialogos['dependencias'] = df_dialogos['dependencias'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998da7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los resultados procesados en archivos CSV\n",
    "\n",
    "df_dialogos.to_csv(\"dialogos_procesados.csv\", index=False)\n",
    "df_argumentos.to_csv(\"argumentos_procesados.csv\", index=False)\n",
    "df_obras.to_csv(\"obras_procesadas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca35417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los DataFrames en formato JSON\n",
    "# se guarda como una lista de objetos (orient)\n",
    "df_dialogos.to_json(\"dialogos_procesados.json\", orient=\"records\") \n",
    "df_argumentos.to_json(\"argumentos_procesados.json\", orient=\"records\")\n",
    "df_obras.to_json(\"obras_procesadas.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
