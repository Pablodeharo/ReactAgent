{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8bce8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2503e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 35 examples [00:00, 404.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogo', 'titulo', 'entidades', 'temas', 'dependencias'],\n",
      "        num_rows: 35\n",
      "    })\n",
      "})\n",
      "{'dialogo': Value(dtype='string', id=None), 'titulo': Value(dtype='string', id=None), 'entidades': Value(dtype='string', id=None), 'temas': Value(dtype='string', id=None), 'dependencias': Value(dtype='string', id=None)}\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "dataset_dialogos = load_dataset('json', data_files=r'C:\\Users\\Lucas\\Desktop\\ReactAgent\\studio\\dialogos_procesados.json')\n",
    "print(dataset_dialogos)\n",
    "print(dataset_dialogos['train'].features)\n",
    "print(type(dataset_dialogos['train']['dependencias'][0]))  # No debería ser necesario, ya que 'dependencias' es una cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ee21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿CUDA disponible?: True\n",
      "Número de GPUs: 1\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Memoria GPU asignada: 1432.41 MB\n",
      "Memoria GPU reservada: 1536.00 MB\n",
      "Memoria libre   : 2663.16 MB\n"
     ]
    }
   ],
   "source": [
    "# Configurar dispositivo como variable global\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"¿CUDA disponible?:\", torch.cuda.is_available())\n",
    "print(\"Número de GPUs:\", torch.cuda.device_count())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No hay GPU disponible\")\n",
    "\n",
    "def check_gpu_memory():\n",
    "    allocated_memory = torch.cuda.memory_allocated()\n",
    "    cached_memory = torch.cuda.memory_reserved()\n",
    "    print(f\"Memoria GPU asignada: {allocated_memory / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"Memoria GPU reservada: {cached_memory / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"Memoria libre   : {torch.cuda.get_device_properties(0).total_memory / 1024 ** 2 - allocated_memory / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "check_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde6d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50265, 768)\n",
       "    (wpe): Embedding(512, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el modelo y el tokenizador\n",
    "model_name = \"PlanTL-GOB-ES/gpt2-base-bne\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, unk_token=\"[UNK]\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0c3c6",
   "metadata": {},
   "source": [
    "El primer parámetro (50265) es el número total de vocabularios en el conjunto de datos de texto al que se va a aplicar la transformación. En otras palabras, representa la cantidad de palabras únicas que hay en el lenguaje o corpus para el cual se creó este objeto Embedding.\n",
    "\n",
    "El segundo parámetro (768) es el número de dimensiones del espacio vectorial que utilizará esta transformación. Es decir, representa la cantidad de valores en cada vector que generará para cada palabra o vocablo del lenguaje. Esto permite obtener información sobre las características semánticas y sintácticas de cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a51e2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tokenizer_dialogo_con_contexto(examples):\n",
    "    \"\"\"\n",
    "    Concatenar las columnas adicionales al texto del diálogo y luego tokenizar.\n",
    "    \"\"\"\n",
    "    dialogo = examples['dialogo']\n",
    "    titulo = examples['titulo']\n",
    "    entidades = examples['entidades']\n",
    "    temas = examples['temas']\n",
    "    dependencias = examples['dependencias']\n",
    "    \n",
    "    # Concatenamos todo el texto para proporcionar contexto adicional\n",
    "    texto_completo = f\"Titulo: {titulo} | Entidades: {entidades} | Temas: {temas} | Dependencias: {dependencias} | Dialogo: {dialogo}\"\n",
    "    \n",
    "    # Tokenizamos el texto completo con un tamaño máximo controlado\n",
    "    tokenized_output = tokenizer(\n",
    "        texto_completo,  # Concatenación de todos los textos\n",
    "        padding='max_length',  # Rellenar hasta la longitud máxima\n",
    "        truncation=True,       # Truncar los textos que exceden el tamaño máximo\n",
    "        max_length=512,        # Establecer un límite máximo de 512 tokens para evitar sobrecarga\n",
    "        return_tensors='pt'    # Asegurarse de que el retorno sea en formato tensor\n",
    "    )\n",
    "    \n",
    "    # Verificar que se ha generado la cantidad correcta de tokens\n",
    "    input_ids = tokenized_output['input_ids']\n",
    "    \n",
    "    # Asegurarse de que la longitud de input_ids es la esperada\n",
    "    if input_ids.size(1) != 512:  # Comprobamos si el tamaño es 512\n",
    "        print(f\"Error en tokenización. Longitud esperada 512, pero se obtuvo {input_ids.size(1)}\")\n",
    "        print(f\"Texto largo: {texto_completo[:200]}... Tokens generados: {input_ids.size(1)}\")\n",
    "    \n",
    "    return tokenized_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb829563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/35 [00:05<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Column 5 named input_ids expected length 35 but got length 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicar la tokenización con contexto\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_dialogos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_dialogo_con_contexto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\dataset_dict.py:886\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 886\u001b[0m     \u001b[43m{\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\dataset_dict.py:887\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    886\u001b[0m     {\n\u001b[1;32m--> 887\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3499\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3497\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[0;32m   3498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3499\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3500\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[0;32m   3501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_writer.py:608\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m--> 608\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_table(pa_table, writer_batch_size)\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\table.pxi:4868\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\table.pxi:4214\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.validate\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Column 5 named input_ids expected length 35 but got length 1"
     ]
    }
   ],
   "source": [
    "# Aplicar la tokenización con contexto\n",
    "tokenized_data = dataset_dialogos.map(tokenizer_dialogo_con_contexto, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fbc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Verificar que las columnas ahora son tensores\n",
    "print(type(tokenized_data['train']['dialogo'][0]))  # Debería ser un tensor de PyTorch\n",
    "print(type(tokenized_data['train']['attention_mask'][0]))  # También un tensor de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7146742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "[2, 26736, 80, 275, 253, 253, 26736, 80, 2558, 989, 23544, 66, 6972, 383, 415, 45386, 313, 1498, 41096, 529, 8296, 24844, 839, 342, 23758, 367, 387, 18628, 369, 4489, 634, 12560, 1857, 468, 66, 361, 6886, 66, 8605, 772, 389, 1066, 415, 45386, 442, 341, 313, 1650, 8209, 334, 355, 5238, 313, 2206, 4623, 66, 341, 361, 8972, 334, 6523, 2942, 68, 415, 45386, 347, 355, 2165, 13551, 394, 43556, 414, 320, 332, 10576, 66, 342, 36865, 840, 341, 2702, 719, 13976, 7341, 68, 16260, 13038, 338, 334, 344, 764, 5159, 313, 403, 2426, 313, 1609, 68, 1893, 11383, 7635, 5493, 344, 6487, 313, 499, 2822, 13892, 81, 347, 11407, 1429, 3658, 5493, 320, 15560, 6468, 68, 547, 11407, 341, 361, 683, 22150, 344, 3057, 66, 361, 683, 2198, 318, 387, 6978, 342, 364, 15557, 66, 342, 509, 347, 2721, 66, 361, 683, 1394, 12436, 796, 1764, 389, 6016, 68, 1893, 347, 737, 8243, 44749, 1609, 509, 514, 8842, 347, 13642, 66, 623, 6077, 845, 442, 9467, 66, 344, 253, 253, 26736, 80, 275, 253, 253, 26736, 80, 2558, 989, 23544, 3655, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264, 50264]\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tipo de datos dentro del dataset tokenizado\n",
    "print(type(tokenized_data['train']['dialogo'][0]))  # Debería ser un tensor de PyTorch\n",
    "print(type(tokenized_data['train']['attention_mask'][0]))  # También un tensor de PyTorch\n",
    "\n",
    "# Comprobar si se convierte correctamente a tensor\n",
    "print(tokenized_data['train']['dialogo'][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a26747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",             \n",
    "    evaluation_strategy=\"epoch\",            # Evaluación después de cada época\n",
    "    save_strategy=\"epoch\",                 # Guardar checkpoints después de cada época\n",
    "    per_device_train_batch_size=16,        # Tamaño del batch por dispositivo (16 en este caso)\n",
    "    num_train_epochs=20,                   # Número de épocas para el entrenamiento\n",
    "    logging_dir=\"./logs\",                  # Directorio para guardar los logs\n",
    "    logging_steps=10,                      # Frecuencia de los logs\n",
    "    save_total_limit=2,                    # Limitar el número de checkpoints guardados\n",
    "    report_to=\"none\",                      # No reportar a plataformas como TensorBoard\n",
    "    remove_unused_columns=False,           # No eliminar columnas no utilizadas\n",
    "    gradient_accumulation_steps=2,         # Acumulación de gradientes cada 2 pasos\n",
    "    learning_rate=1e-5,                    # Tasa de aprendizaje ajustada\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de evaluación\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy = (predictions == labels).float().mean()\n",
    "    return {'accuracy': accuracy.item()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
